{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4f935-7230-4c1f-ad3f-d46d08b7b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore various formating outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fa0ad8-4c04-4e22-90eb-a209793551b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n",
      "All set!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import litellm\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"imported\")\n",
    "\n",
    "AI_MODEL=\"openai/gpt-4o-mini\" # OR: openai/gpt-4o-mini /anthropic/claude-haiku-4-5-20251001/ change between them to observe the effects!\n",
    "MAX_TOKENS_DEFAULT = 500\n",
    "\n",
    "def get_completion(prompt_or_messages, model=AI_MODEL, max_tokens=MAX_TOKENS_DEFAULT, **kwargs):\n",
    "    # If user passes a plain string, wrap it in a messages list\n",
    "    if isinstance(prompt_or_messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt_or_messages}]\n",
    "    else:\n",
    "        messages = prompt_or_messages\n",
    "\n",
    "    # Guard: avoid sending empty messages\n",
    "    if not isinstance(messages, list) or len(messages) == 0:\n",
    "        raise ValueError(f\"'messages' must be a non-empty list. Got: {messages}\")\n",
    "\n",
    "    resp = litellm.completion(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        **kwargs\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "print(\"All set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0148328e-3fc0-41aa-ac59-0de0f6897f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review = dedent(\"\"\"\n",
    "I'm trilled about Quantumleap server! It faster than Superman. The setup was a bit tricky, but the support team was fantastic!.\n",
    "5***** starts out of 5*****. I'll recommand to all!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505182d7-e55e-4e0f-8714-4226c733127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_just_tell_AI_what_to_do = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": dedent(f\"\"\"\n",
    "        Analyse the follosinw review and output your finding as JSON.\n",
    "        Include the product name, a short summary and a sentiment score.\n",
    "\n",
    "        <review>\n",
    "        {user_review}\n",
    "        </review>\n",
    "        \"\"\")\n",
    "    }\n",
    "]\n",
    "\n",
    "response_just_tell_AI_what_to_do = get_completion(prompt_just_tell_AI_what_to_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdf0128-195a-4dac-bf82-4012e38fa0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"product_name\": \"Quantumleap server\",\n",
      "  \"summary\": \"The reviewer is thrilled with the Quantumleap server, noting its speed and fantastic support team, despite finding the setup a bit tricky. They highly recommend it.\",\n",
      "  \"sentiment_score\": 5\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response_just_tell_AI_what_to_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4258177-cbd1-4d5b-b8b9-6b08f50c193d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
